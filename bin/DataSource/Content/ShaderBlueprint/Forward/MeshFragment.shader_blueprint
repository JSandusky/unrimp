/*********************************************************\
 * Copyright (c) 2012-2017 The Unrimp Team
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy of this software
 * and associated documentation files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all copies or
 * substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
 * BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
\*********************************************************/


//[-------------------------------------------------------]
//[ Definitions                                           ]
//[-------------------------------------------------------]
@includepiece(ShaderPiece/Core.asset)
	@insertpiece(SetCrossPlatformSettings)
@includepiece(ShaderPiece/MotionBlur.asset)


//[-------------------------------------------------------]
//[ Define pieces                                         ]
//[-------------------------------------------------------]
// TODO(co) Define this outside
@piece(MaximumNumberOfMaterials)2@end


//[-------------------------------------------------------]
//[ Input / output                                        ]
//[-------------------------------------------------------]
// Attribute input / output
INPUT_BEGIN
	INPUT_TEXTURE_COORDINATE_NOINTERPOLATION(1, uint,   AssignedMaterialSlotVS,			0)	// The assigned material slot inside the material uniform buffer
	INPUT_TEXTURE_COORDINATE				(2, float2, TexCoordVS,						1)	// Texture coordinate
	INPUT_TEXTURE_COORDINATE				(3, float3, TangentFrame0VS,				2)	// Tangent frame
	INPUT_TEXTURE_COORDINATE				(4, float3, TangentFrame1VS,				3)	// Tangent frame
	INPUT_TEXTURE_COORDINATE				(5, float3, TangentFrame2VS,				4)	// Tangent frame
	INPUT_TEXTURE_COORDINATE				(6, float3, WorldSpacePositionVS,			5)	// World space position
	INPUT_TEXTURE_COORDINATE				(7, float3, PreviousClipSpacePositionVS,	6)	// Previous clip space position
	DECLARE_FRAGMENT_POSITION
	DECLARE_COVERAGE_MASK
	DECLARE_IS_FRONT_FACE
INPUT_END
OUTPUT_BEGIN
	OUTPUT_COLOR(0)	// rgb = diffuse color, a = alpha
	OUTPUT_COLOR(1)	// rgb = view space normal
	OUTPUT_COLOR(2)	// rg  = screen space velocity
OUTPUT_END

// Uniform buffers
struct PassDataStruct
{
	float4x4 WorldSpaceToClipSpaceMatrix;
	float4x4 PreviousWorldSpaceToClipSpaceMatrix;
	float4x4 ShadowMatrix;
	float4   ShadowCascadeOffsets[4];
	float4   ShadowCascadeScales[4];
	float4   ShadowCascadeSplits;
	float4	 ViewSpaceToWorldSpaceQuaternion;
	float4	 WorldSpaceToViewSpaceQuaternion;
	float3	 ViewSpaceSunlightDirection;
	float	 Wetness;
	float3	 AmbientColor;
	float3	 SunlightColor;
	float3   CameraWorldSpacePosition;
	float3	 LightClustersScale;
	float3	 LightClustersBias;
	uint	 FullCoverageMask;
	float2   ViewportSize;
	float2   ProjectionParameters;
};
UNIFORM_BUFFER_BEGIN(0, 0, PassUniformBuffer, 0)
	PassDataStruct PassData;
UNIFORM_BUFFER_END
struct Material
{
	float3 DiffuseColor;
	float  Roughness;
	float  Metallic;
	float  AlphaReference;
	float  EmissiveIntensity;
};
UNIFORM_BUFFER_BEGIN(1, 0, MaterialUniformBuffer, 1)
	Material Materials[FAST_SHADER_BUILD_HACK(@insertpiece(MaximumNumberOfMaterials))];
UNIFORM_BUFFER_END

// Texture buffers: We need to start at texture unit 1 instead of texture unit 0 because the vertex shader has an instance texture buffer bound at texture unit 0 (OpenGL shares those bindings accros all shader stages while Direct3D doesn't)
TEXTURE_BUFFER(3, 0, float4, LightTextureBuffer, 1)	// "LIGHT"

// Textures
TEXTURE_2D_ARRAY(4, 0, ShadowMap, 2)
TEXTURE_CUBE(4, 1, ReflectionCubeMap, 3)
TEXTURE_3D_UINT(4, 2, LightClustersMap3D, 4)
TEXTURE_2D(4, 3, _drgb_nxa, 5)		// RGB channel = Diffuse map ("_d"-postfix), A channel = x component of normal map ("_n"-postfix)
TEXTURE_2D(4, 4, _hr_rg_mb_nya, 6)	// R channel = Height map ("_h"-postfix), G channel = Roughness map ("_r"-postfix), B channel = Metallic map ("_m"-postfix), A channel = y component of normal map ("_n"-postfix)
@property(UseAlphaMap)
	TEXTURE_2D(4, 5, AlphaMap, 7)
@end
@property(UseEmissiveMap)
	TEXTURE_2D(4, 6, EmissiveMap, 8)
@end

// Samplers
SAMPLER_STATE(5, 0, SamplerPoint, 0)
SAMPLER_STATE(5, 1, SamplerLinear, 1)


//[-------------------------------------------------------]
//[ Functions                                             ]
//[-------------------------------------------------------]
@includepiece(ShaderPiece/TangentFrame.asset)
	@insertpiece(DefineGetTangentFrame)
@includepiece(ShaderPiece/PhysicallyBasedShading.asset)
	@property(HighQualityLighting)
		@insertpiece(DefinePhysicallyBasedShading)
	@end
	@property(!HighQualityLighting)
		@insertpiece(DefineBlinnPhongBasedShading)
	@end
@includepiece(ShaderPiece/Depth.asset)
	@insertpiece(DefineGetLinearDepthByFragmentDepth)
@includepiece(ShaderPiece/ExponentialShadow.asset)
	@insertpiece(DefineExponentialShadow)
@includepiece(ShaderPiece/Shadow.asset)
	@insertpiece(DefineCalculateShadowVisibility)
	@insertpiece(DefineShadowDebugging)


//[-------------------------------------------------------]
//[ Main                                                  ]
//[-------------------------------------------------------]
MAIN_BEGIN
	// Get the used material
	Material material = Materials[MAIN_INPUT(AssignedMaterialSlotVS)];

	// Perform alpha map based fragment rejection
	@property(UseAlphaMap)
		if (material.AlphaReference >= SAMPLE_2D(AlphaMap, SamplerLinear, MAIN_INPUT(TexCoordVS)).r)
		{
			discard;
		}
	@end

	// Read channel packed texture data
	// -> "_drgb_nxa" = RGB channel = Diffuse map ("_d"-postfix), A channel = x component of normal map ("_n"-postfix)
	// -> "_hr_rg_mb_nya" = R channel = Height map ("_h"-postfix), G channel = Roughness map ("_r"-postfix), B channel = Metallic map ("_m"-postfix), A channel = y component of normal map ("_n"-postfix)
	float4 value_drgb_nxa = SAMPLE_2D(_drgb_nxa, SamplerLinear, MAIN_INPUT(TexCoordVS));
	float4 value_hr_rg_mb_nya = SAMPLE_2D(_hr_rg_mb_nya, SamplerLinear, MAIN_INPUT(TexCoordVS));

	// Get diffuse, roughness and metallic
	float3 diffuse = material.DiffuseColor * value_drgb_nxa.rgb;
	float roughness = material.Roughness * value_hr_rg_mb_nya.g;
	float metallic = SATURATE(PassData.Wetness + material.Metallic + value_hr_rg_mb_nya.b);

	// Get the per fragment normal [0..1] by using a tangent space BC5/3DC/ATI2N stored normal map
	// -> See "Real-Time Normal Map DXT Compression" -> "3.3 Tangent-Space 3Dc" - http://www.nvidia.com/object/real-time-normal-map-dxt-compression.html
	float3 viewSpaceNormal;
	viewSpaceNormal.x = value_drgb_nxa.a * 2.0f - 1.0f;
	viewSpaceNormal.y = value_hr_rg_mb_nya.a * 2.0f - 1.0f;
	viewSpaceNormal.z = sqrt(1.0f - dot(viewSpaceNormal.xy, viewSpaceNormal.xy));
	// TODO(co) Get rid of this
	if (isnan(viewSpaceNormal.z))
	{
		viewSpaceNormal.z = 1.0f;
	}

	// Transform the tangent space normal into view space
	viewSpaceNormal = normalize(viewSpaceNormal.x * MAIN_INPUT(TangentFrame0VS) + viewSpaceNormal.y * MAIN_INPUT(TangentFrame1VS) + viewSpaceNormal.z * MAIN_INPUT(TangentFrame2VS));

	// Handle two sided lighting
	// -> It's not worth to add additional expensive shader combinations just for this tiny thing
	viewSpaceNormal = IS_FRONT_FACE ? viewSpaceNormal : -viewSpaceNormal;

	// Derive data
	float3 worldSpaceNormal = MultiplyQuaternionVector(PassData.ViewSpaceToWorldSpaceQuaternion, viewSpaceNormal);
	float3 worldSpacePosition = MAIN_INPUT(WorldSpacePositionVS);

	// Ambient term
	float3 color = diffuse * (PassData.AmbientColor.rgb + CalculateHemisphereLighting(worldSpaceNormal.xyz, PassData.AmbientColor.rgb * 0.7f, PassData.AmbientColor.rgb * 0.2f));

	// Get view space incident vector
	float3 viewSpaceIncident = normalize(PassData.CameraWorldSpacePosition - worldSpacePosition);
	viewSpaceIncident = MultiplyQuaternionVector(PassData.WorldSpaceToViewSpaceQuaternion, viewSpaceIncident);

	// Directional sunlight, our primary light
	float shadowVisibility = CalculateShadowVisibility(worldSpacePosition, GetLinearDepthByFragmentDepth(FRAGMENT_POSITION.z));
	if (shadowVisibility > 0.0f)
	{
		color += shadowVisibility * CalculateLighting(diffuse, roughness, metallic, viewSpaceNormal, viewSpaceIncident, PassData.ViewSpaceSunlightDirection, PassData.SunlightColor);
	}

	// Perform clustered shading
	@insertpiece(PerformClusteredShading)

	// Emissive term
	@property(UseEmissiveMap)
		color += SAMPLE_2D(EmissiveMap, SamplerLinear, MAIN_INPUT(TexCoordVS)).rgb * material.EmissiveIntensity;
	@end

	// Complex pixel detection
	// -> "Antialiased Deferred Rendering" - https://docs.nvidia.com/gameworks/content/gameworkslibrary/graphicssamples/d3d_samples/antialiaseddeferredrendering.htm
	float edgePixel = (COVERAGE_MASK != PassData.FullCoverageMask) ? 1.0f : 0.0f;

	// Calculate screen space velocity
	@insertpiece(DefineCalculateScreenSpaceVelocity)

	// Done
	MAIN_OUTPUT_COLOR(0) = float4(color, edgePixel);
	MAIN_OUTPUT_COLOR(1) = float4(viewSpaceNormal, edgePixel);
	MAIN_OUTPUT_COLOR(2) = float4(velocity.x, velocity.y, 0.0f, 0.0f);
MAIN_END
