/*********************************************************\
 * Copyright (c) 2012-2017 The Unrimp Team
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy of this software
 * and associated documentation files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all copies or
 * substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
 * BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
\*********************************************************/


//[-------------------------------------------------------]
//[ Definitions                                           ]
//[-------------------------------------------------------]
@includepiece($ProjectName/ShaderPiece/Core.asset)
	@insertpiece(SetCrossPlatformSettings)


//[-------------------------------------------------------]
//[ Input / output                                        ]
//[-------------------------------------------------------]
// Attribute input / output
INPUT_BEGIN
	INPUT_TEXTURE_COORDINATE(1, float2, TexCoordVS, 0)	// Texture coordinate
INPUT_END
OUTPUT_BEGIN
	OUTPUT_COLOR(0)
OUTPUT_END

// Uniform buffers
struct PassDataStruct
{
	float2 InverseViewportSize;
	float2 ProjectionParameters;
	float  NearBlurDepth;
	float  FocalPlaneDepth;
	float  FarBlurDepth;
	float  BlurrinessCutoff;	// Blurriness cutoff constant for objects behind the focal plane
};
UNIFORM_BUFFER_BEGIN(0, 0, PassUniformBuffer, 0)
	PassDataStruct PassData;
UNIFORM_BUFFER_END

// Textures
TEXTURE_2D(1, 0, ColorMap, 0)
@property(NumberOfMultisamples)
	TEXTURE_2D_MS(1, 1, DepthMap, @value(NumberOfMultisamples), 1)
@end
@property(!NumberOfMultisamples)
	TEXTURE_2D(1, 1, DepthMap, 1)
@end
TEXTURE_2D(1, 2, BlurMap, 2)	// Blurred low resolution version of the color map

// Samplers
SAMPLER_STATE(2, 0, SamplerPointClamp, 0)
SAMPLER_STATE(2, 1, SamplerLinear, 1)


//[-------------------------------------------------------]
//[ Functions                                             ]
//[-------------------------------------------------------]
@includepiece($ProjectName/ShaderPiece/Depth.asset)
	@insertpiece(DefineGetLinearDepth)
	@insertpiece(DefineGetDepthFromDepthMap)
	@insertpiece(DefineGetLinearDepthFromDepthMap)

float ConvertDepth(float linearDepth)
{
	float depth = 0.0f;
	if (linearDepth < PassData.FocalPlaneDepth)
	{
		// Scale depth value between near blur distance and focal distance to [-1, 0] range
		depth = (linearDepth - PassData.FocalPlaneDepth) / (PassData.FocalPlaneDepth - PassData.NearBlurDepth);
	}
	else
	{
		// Scale depth value between focal distance and far blur distance to [0, 1] range
		depth = (linearDepth - PassData.FocalPlaneDepth) / (PassData.FarBlurDepth - PassData.FocalPlaneDepth);

		// Clamp the far blur to a maximum blurriness
		depth = clamp(depth, 0.0f, PassData.BlurrinessCutoff);
	}

	// Scale and bias into [0, 1] range
	depth = 0.5f * depth + 0.5f;
	return depth;
}

float4 CalculateSum(float2 textureCoordinate, int sampleIndex)
{
	// Depth of field basing on https://developer.amd.com/wordpress/media/2012/10/Scheuermann_DepthOfField.pdf
	float2 pixelSizeScene = PassData.InverseViewportSize;	// Pixel size of full resolution image
	float2 pixelSizeBlur = float2(1.0f, 1.0f) / CAST_TO(GET_TEXTURE_2D_SIZE(BlurMap), float2);	// Pixel size of downsampled and blurred image
	float2 poisson[12];	// Containts poisson-distributed positions on the unit circle for 12 taps
	poisson[ 0] = float2( 0.00f,  0.00f);
	poisson[ 1] = float2( 0.07f, -0.45f);
	poisson[ 2] = float2(-0.15f, -0.33f);
	poisson[ 3] = float2( 0.35f, -0.32f);
	poisson[ 4] = float2(-0.39f, -0.26f);
	poisson[ 5] = float2( 0.10f, -0.23f);
	poisson[ 6] = float2( 0.36f, -0.12f);
	poisson[ 7] = float2(-0.31f, -0.01f);
	poisson[ 8] = float2(-0.38f,  0.22f);
	poisson[ 9] = float2( 0.36f,  0.23f);
	poisson[10] = float2(-0.13f,  0.29f);
	poisson[11] = float2( 0.14f,  0.41f);

	// Maximum circle of confusion (CoC) radius and diameter in pixels
	float2 maxCoC = float2(5.0f, 10.0f);

	// Scale factor for minimum CoC size on low resolution image
	float radiusScale = 0.4f;

	// Get depth of center tap and convert it into blur radius in pixels
	float centerDepth	  = ConvertDepth(GetLinearDepthFromDepthMap(textureCoordinate, sampleIndex));
	float discRadiusScene = abs(centerDepth * maxCoC.y - maxCoC.x);
	float discRadiusBlur  = discRadiusScene * radiusScale;	// Radius on low resolution image

	float4 sum = float4(0.0f, 0.0f, 0.0f, 0.0f);
	for (int i = 0; i < 12; ++i)
	{
		// Compute texture coordinates
		float4 coordScene = float4(textureCoordinate + (pixelSizeScene * poisson[i] * discRadiusScene), 0.0f, 0.0f);
		float4 coordBlur = float4(textureCoordinate + (pixelSizeBlur * poisson[i] * discRadiusBlur), 0.0f, 0.0f);

		// Fetch taps and depth
		float4 tapScene = SAMPLE_2D_LOD(ColorMap, SamplerPointClamp, coordScene);
		float tapDepth = ConvertDepth(GetLinearDepthFromDepthMap(coordScene.xy, sampleIndex));
		float4 tapBlur = SAMPLE_2D_LOD(BlurMap, SamplerLinear, coordBlur);

		// Mix low and high resolution taps based on tap blurriness
		float blurAmount = abs(tapDepth * 2.0f - 1.0f);	// Put blurriness into [0, 1]
		float4 tap = LERP(tapScene, tapBlur, blurAmount);

		// "smart" blur ignores taps that are closer than the center tap and in focus
		float factor = (tapDepth >= centerDepth) ? 1.0f : abs(tapDepth * 2.0f - 1.0f);

		// Accumulate
		sum.rgb += tap.rgb * factor;
		sum.a += factor;
	}

	// Done
	return sum;
}


//[-------------------------------------------------------]
//[ Main                                                  ]
//[-------------------------------------------------------]
MAIN_BEGIN
	@property(NumberOfMultisamples)
		// Complex pixel detection
		float4 sum;
		if (0 != SAMPLE_2D_LOD(ColorMap, SamplerPointClamp, float4(MAIN_INPUT(TexCoordVS), 0.0f, 0.0f)).a)
		{
			// Custom MSAA resolve
			sum = float4(0.0f, 0.0f, 0.0f, 0.0f);
			@foreach(NumberOfMultisamples, i, 0)
			{
				sum += CalculateSum(MAIN_INPUT(TexCoordVS), @i);
			}
			@end
		}
		else
		{
			sum = CalculateSum(MAIN_INPUT(TexCoordVS), 0);
		}
	@end
	@property(!NumberOfMultisamples)
		float4 sum = CalculateSum(MAIN_INPUT(TexCoordVS), 0);
	@end

	// Done
	MAIN_OUTPUT_COLOR(0) = float4(sum.rgb / sum.a, 1.0f);
MAIN_END
